# è§†è§‰å¤§æ¨¡å‹æµ‹è¯•åˆ†æåŠŸèƒ½

## åŠŸèƒ½æ¦‚è¿°

æµ‹è¯•æ‰§è¡Œå®Œæˆåï¼Œç³»ç»Ÿä¼šä½¿ç”¨è§†è§‰å¤§æ¨¡å‹ï¼ˆVision LLMï¼‰åˆ†ææ¯ä¸ªæ­¥éª¤çš„æˆªå›¾ï¼Œä¸é¢„æœŸç»“æœå¯¹æ¯”ï¼Œæ™ºèƒ½åˆ¤æ–­æµ‹è¯•æ˜¯å¦é€šè¿‡ã€‚

## æ ¸å¿ƒæ”¹è¿›

### 1. **è§†è§‰åˆ†æ** ğŸ‘ï¸
- âœ… å¯¹æ¯ä¸ªæµ‹è¯•æ­¥éª¤çš„æˆªå›¾ä½¿ç”¨è§†è§‰å¤§æ¨¡å‹åˆ†æ
- âœ… è¯†åˆ«æˆªå›¾ä¸­çš„UIå…ƒç´ ã€æ–‡æœ¬ã€å¸ƒå±€ç­‰
- âœ… åˆ¤æ–­æˆªå›¾å†…å®¹æ˜¯å¦ç¬¦åˆé¢„æœŸç»“æœ

### 2. **æ™ºèƒ½åˆ¤å®š** ğŸ¤–
- âœ… ç»¼åˆæ‰€æœ‰æˆªå›¾åˆ†æç»“æœ
- âœ… ç»“åˆæ­¥éª¤æ‰§è¡ŒçŠ¶æ€
- âœ… ç»™å‡ºæœ€ç»ˆæµ‹è¯•åˆ¤å®šï¼ˆé€šè¿‡/å¤±è´¥/æœªçŸ¥ï¼‰

### 3. **è¯¦ç»†åé¦ˆ** ğŸ“
- âœ… æ¯ä¸ªæ­¥éª¤çš„è§†è§‰è§‚å¯Ÿç»“æœ
- âœ… å‘ç°çš„é—®é¢˜åˆ—è¡¨
- âœ… åˆ¤å®šç½®ä¿¡åº¦å’Œç†ç”±

## å·¥ä½œæµç¨‹

```
æ‰§è¡Œæµ‹è¯•
  â†“
ç”Ÿæˆæ¯ä¸ªæ­¥éª¤çš„æˆªå›¾
  â†“
å¯¹æ¯ä¸ªæˆªå›¾è°ƒç”¨è§†è§‰å¤§æ¨¡å‹
  â†“
è§†è§‰æ¨¡å‹åˆ†æï¼š
  - è§‚å¯Ÿåˆ°çš„UIå†…å®¹
  - æ˜¯å¦ç¬¦åˆé¢„æœŸ
  - å‘ç°çš„é—®é¢˜
  â†“
ç»¼åˆæ‰€æœ‰åˆ†æç»“æœ
  â†“
åˆ¤å®šæµ‹è¯•ç»“æœï¼š
  - passed: æ‰€æœ‰æ­¥éª¤ç¬¦åˆé¢„æœŸ
  - failed: å¤šæ•°æ­¥éª¤ä¸ç¬¦åˆé¢„æœŸ
  - unknown: éƒ¨åˆ†æ­¥éª¤ä¸ç¡®å®š
  â†“
ä¿å­˜åˆ¤å®šç»“æœå’Œè§‚å¯Ÿè®°å½•
```

## åç«¯å®ç°

### ä¿®æ”¹æ–‡ä»¶

**æ–‡ä»¶**: `backend/app/services/llm_service.py`

#### 1. ä¿®æ”¹ `analyze_test_result` æ–¹æ³•

```python
def analyze_test_result(self, expected_result: str, step_screenshots: List[str], 
                        console_logs: List[str], step_statuses: List[Dict[str, Any]]) -> Dict[str, Any]:
    # å¦‚æœæ²¡æœ‰æˆªå›¾ï¼Œä½¿ç”¨åŸºç¡€åˆ¤å®š
    if not step_screenshots:
        return self._analyze_without_vision(expected_result, console_logs, step_statuses)
    
    # ä½¿ç”¨è§†è§‰å¤§æ¨¡å‹åˆ†ææ¯ä¸ªæˆªå›¾
    screenshot_analyses = []
    for idx, screenshot_path in enumerate(step_screenshots):
        try:
            analysis = self._analyze_screenshot_with_vision(
                screenshot_path, expected_result, 
                step_statuses[idx] if idx < len(step_statuses) else None
            )
            screenshot_analyses.append({
                "step_index": idx + 1,
                "screenshot_path": screenshot_path,
                "analysis": analysis
            })
        except Exception as e:
            screenshot_analyses.append({
                "step_index": idx + 1,
                "screenshot_path": screenshot_path,
                "analysis": {"error": str(e)}
            })
    
    # ç»¼åˆæ‰€æœ‰åˆ†æç»“æœ
    return self._ç»¼åˆåˆ¤å®š(expected_result, screenshot_analyses, console_logs, step_statuses)
```

#### 2. æ–°å¢ `_analyze_screenshot_with_vision` æ–¹æ³•

```python
def _analyze_screenshot_with_vision(self, screenshot_path: str, expected_result: str, 
                                     step_status: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    import base64
    
    # è¯»å–æˆªå›¾å¹¶è½¬ä¸ºbase64
    with open(screenshot_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode("utf-8")
    
    step_desc = step_status.get("description", "") if step_status else ""
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„UIæµ‹è¯•åˆ†æä¸“å®¶ã€‚è¯·åˆ†æè¿™å¼ æˆªå›¾ã€‚

æ­¥éª¤æè¿°: {step_desc}
é¢„æœŸç»“æœ: {expected_result}

è¯·æè¿°ä½ åœ¨æˆªå›¾ä¸­çœ‹åˆ°çš„å†…å®¹ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚è¿”å›JSONæ ¼å¼ï¼š
{{
  "observation": "å…·ä½“è§‚å¯Ÿåˆ°çš„å†…å®¹",
  "matches_expectation": true/false,
  "issues": ["å‘ç°çš„é—®é¢˜åˆ—è¡¨"]
}}"""
    
    # è°ƒç”¨è§†è§‰å¤§æ¨¡å‹ï¼ˆOpenAI Vision APIï¼‰
    if self.provider in ["openai", "dashscope"]:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}"}}
                ]
            }],
            max_tokens=500
        )
        result_text = response.choices[0].message.content
        return json.loads(result_text.strip())
```

#### 3. æ–°å¢ `_ç»¼åˆåˆ¤å®š` æ–¹æ³•

```python
def _ç»¼åˆåˆ¤å®š(self, expected_result: str, screenshot_analyses: List[Dict], 
            console_logs: List[str], step_statuses: List[Dict[str, Any]]) -> Dict[str, Any]:
    # ç»Ÿè®¡ç¬¦åˆé¢„æœŸçš„æˆªå›¾æ•°é‡
    matching_count = sum(1 for a in screenshot_analyses 
                        if a.get("analysis", {}).get("matches_expectation") == True)
    total_count = len(screenshot_analyses)
    
    # æ”¶é›†æ‰€æœ‰è§‚å¯Ÿ
    observations = []
    for analysis in screenshot_analyses:
        if "analysis" in analysis and "observation" in analysis["analysis"]:
            observations.append({
                "step_index": analysis["step_index"],
                "type": "visual",
                "description": analysis["analysis"]["observation"],
                "severity": "error" if not analysis["analysis"].get("matches_expectation") else "info"
            })
    
    # åˆ¤å®šé€»è¾‘
    if matching_count == total_count:
        verdict = "passed"
        confidence = 0.9
        reason = f"æ‰€æœ‰{total_count}ä¸ªæ­¥éª¤çš„æˆªå›¾åˆ†æéƒ½ç¬¦åˆé¢„æœŸç»“æœ"
    elif matching_count >= total_count * 0.7:
        verdict = "unknown"
        confidence = 0.6
        reason = f"{matching_count}/{total_count}ä¸ªæ­¥éª¤ç¬¦åˆé¢„æœŸï¼Œéƒ¨åˆ†æ­¥éª¤å­˜åœ¨é—®é¢˜"
    else:
        verdict = "failed"
        confidence = 0.85
        reason = f"åªæœ‰{matching_count}/{total_count}ä¸ªæ­¥éª¤ç¬¦åˆé¢„æœŸï¼Œæµ‹è¯•å¤±è´¥"
    
    return {
        "verdict": verdict,
        "confidence": confidence,
        "reason": reason,
        "observations": observations
    }
```

## è§†è§‰æ¨¡å‹æ”¯æŒ

### æ”¯æŒçš„æ¨¡å‹

| æä¾›å•† | æ¨¡å‹ | è¯´æ˜ |
|--------|------|------|
| OpenAI | gpt-4-vision-preview | GPT-4 Vision |
| OpenAI | gpt-4o | æœ€æ–°å¤šæ¨¡æ€æ¨¡å‹ |
| DashScope | qwen-vl-plus | é˜¿é‡Œåƒé—®è§†è§‰æ¨¡å‹ |

### æ¨¡å‹é…ç½®

åœ¨é¡¹ç›®é…ç½®ä¸­æŒ‡å®šæ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼š

```json
{
  "llm_provider": "openai",
  "llm_model": "gpt-4o",
  "llm_api_key": "sk-...",
  "llm_base_url": "https://api.openai.com/v1"
}
```

## åˆ†æç¤ºä¾‹

### è¾“å…¥

**æ­¥éª¤1æˆªå›¾**: ç™»å½•é¡µé¢
**æ­¥éª¤æè¿°**: "æ‰“å¼€ç™»å½•é¡µé¢"
**é¢„æœŸç»“æœ**: "æ˜¾ç¤ºç™»å½•è¡¨å•ï¼ŒåŒ…å«ç”¨æˆ·åå’Œå¯†ç è¾“å…¥æ¡†"

### Vision LLM åˆ†æ

```json
{
  "observation": "æˆªå›¾æ˜¾ç¤ºä¸€ä¸ªç™»å½•é¡µé¢ï¼ŒåŒ…å«'ç”¨æˆ·å'å’Œ'å¯†ç 'ä¸¤ä¸ªè¾“å…¥æ¡†ï¼Œä»¥åŠä¸€ä¸ªè“è‰²çš„'ç™»å½•'æŒ‰é’®ã€‚é¡µé¢é¡¶éƒ¨æœ‰ç½‘ç«™Logoã€‚",
  "matches_expectation": true,
  "issues": []
}
```

### æœ€ç»ˆåˆ¤å®š

å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½ç¬¦åˆé¢„æœŸï¼š

```json
{
  "verdict": "passed",
  "confidence": 0.9,
  "reason": "æ‰€æœ‰3ä¸ªæ­¥éª¤çš„æˆªå›¾åˆ†æéƒ½ç¬¦åˆé¢„æœŸç»“æœ",
  "observations": [
    {
      "step_index": 1,
      "type": "visual",
      "description": "æˆªå›¾æ˜¾ç¤ºç™»å½•é¡µé¢ï¼ŒåŒ…å«ç”¨æˆ·åå’Œå¯†ç è¾“å…¥æ¡†",
      "severity": "info"
    },
    {
      "step_index": 2,
      "type": "visual",
      "description": "æˆåŠŸå¡«å†™ç”¨æˆ·åå’Œå¯†ç ",
      "severity": "info"
    },
    {
      "step_index": 3,
      "type": "visual",
      "description": "ç‚¹å‡»ç™»å½•åè·³è½¬åˆ°ä»ªè¡¨æ¿é¡µé¢",
      "severity": "info"
    }
  ]
}
```

## åˆ¤å®šè§„åˆ™

### Passedï¼ˆé€šè¿‡ï¼‰
- æ¡ä»¶ï¼š100% æ­¥éª¤ç¬¦åˆé¢„æœŸ
- ç½®ä¿¡åº¦ï¼š0.9
- ç¤ºä¾‹ï¼š3/3 æ­¥éª¤ç¬¦åˆé¢„æœŸ

### Unknownï¼ˆæœªçŸ¥ï¼‰
- æ¡ä»¶ï¼š70%-99% æ­¥éª¤ç¬¦åˆé¢„æœŸ
- ç½®ä¿¡åº¦ï¼š0.6
- ç¤ºä¾‹ï¼š2/3 æ­¥éª¤ç¬¦åˆé¢„æœŸ

### Failedï¼ˆå¤±è´¥ï¼‰
- æ¡ä»¶ï¼š< 70% æ­¥éª¤ç¬¦åˆé¢„æœŸ
- ç½®ä¿¡åº¦ï¼š0.85
- ç¤ºä¾‹ï¼š1/3 æ­¥éª¤ç¬¦åˆé¢„æœŸ

## ä¼˜åŠ¿

1. **æ™ºèƒ½åˆ†æ** - ä¸ä»…çœ‹æ­¥éª¤çŠ¶æ€ï¼Œè¿˜åˆ†æå®é™…UIæ•ˆæœ
2. **å‡†ç¡®åˆ¤å®š** - åŸºäºè§†è§‰è¯æ®ï¼Œæ›´æ¥è¿‘äººå·¥æµ‹è¯•
3. **è¯¦ç»†åé¦ˆ** - æä¾›æ¯ä¸ªæ­¥éª¤çš„è§‚å¯Ÿç»“æœ
4. **è‡ªåŠ¨åŒ–** - æ— éœ€äººå·¥æŸ¥çœ‹æˆªå›¾
5. **å¯è¿½æº¯** - ä¿ç•™æ‰€æœ‰è§‚å¯Ÿè®°å½•ä¾›å®¡æŸ¥

## ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: UI å¸ƒå±€éªŒè¯
- éªŒè¯é¡µé¢å…ƒç´ æ˜¯å¦æ­£ç¡®æ˜¾ç¤º
- æ£€æŸ¥å¸ƒå±€æ˜¯å¦ç¬¦åˆè®¾è®¡
- å‘ç°è§†è§‰ç¼ºé™·

### åœºæ™¯ 2: æ–‡æœ¬å†…å®¹éªŒè¯
- éªŒè¯é¡µé¢æ–‡æœ¬æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥æç¤ºä¿¡æ¯æ˜¯å¦æ˜¾ç¤º
- ç¡®è®¤é”™è¯¯æ¶ˆæ¯å†…å®¹

### åœºæ™¯ 3: äº¤äº’ç»“æœéªŒè¯
- éªŒè¯ç‚¹å‡»åçš„é¡µé¢å˜åŒ–
- æ£€æŸ¥è¡¨å•æäº¤åçš„åé¦ˆ
- ç¡®è®¤å¯¼èˆªæ˜¯å¦æ­£ç¡®

## æ³¨æ„äº‹é¡¹

âš ï¸ **é‡è¦æç¤º**:

1. **æ¨¡å‹é€‰æ‹©**: å¿…é¡»ä½¿ç”¨æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼ˆå¦‚ gpt-4o, qwen-vl-plusï¼‰
2. **API æˆæœ¬**: Vision API è°ƒç”¨æˆæœ¬è¾ƒé«˜ï¼Œæ¯ä¸ªæˆªå›¾éƒ½ä¼šè°ƒç”¨
3. **å¤„ç†æ—¶é—´**: è§†è§‰åˆ†æéœ€è¦é¢å¤–æ—¶é—´ï¼ˆæ¯å¼ å›¾ 2-5 ç§’ï¼‰
4. **å›¾ç‰‡è´¨é‡**: æˆªå›¾è´¨é‡å½±å“åˆ†æå‡†ç¡®åº¦
5. **ç½‘ç»œè¦æ±‚**: éœ€è¦ç¨³å®šçš„ç½‘ç»œä¸Šä¼ æˆªå›¾åˆ° LLM API

## æœ€ä½³å®è·µ

1. **æ¸…æ™°çš„é¢„æœŸç»“æœ**: ç¼–å†™å…·ä½“ã€æ˜ç¡®çš„é¢„æœŸç»“æœæè¿°
2. **å…³é”®æ­¥éª¤æˆªå›¾**: ç¡®ä¿å…³é”®éªŒè¯ç‚¹éƒ½æœ‰æˆªå›¾
3. **åˆç†æ­¥éª¤æ•°**: é¿å…è¿‡å¤šæ­¥éª¤å¯¼è‡´æˆæœ¬è¿‡é«˜
4. **æ£€æŸ¥åˆ†æç»“æœ**: æŸ¥çœ‹observationsäº†è§£è¯¦ç»†åˆ¤å®šä¾æ®
5. **è°ƒæ•´åˆ¤å®šé˜ˆå€¼**: æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´70%çš„é˜ˆå€¼

## åç»­ä¼˜åŒ–å»ºè®®

1. **ç¼“å­˜æœºåˆ¶**: ç›¸åŒæˆªå›¾é¿å…é‡å¤åˆ†æ
2. **å¹¶è¡Œåˆ†æ**: å¤šä¸ªæˆªå›¾å¹¶è¡Œè°ƒç”¨Vision API
3. **åŒºåŸŸæ ‡æ³¨**: åœ¨æˆªå›¾ä¸Šæ ‡æ³¨å…³é”®å…ƒç´ 
4. **å¯¹æ¯”åˆ†æ**: å¯¹æ¯”æœŸæœ›æˆªå›¾å’Œå®é™…æˆªå›¾
5. **è‡ªå®šä¹‰è§„åˆ™**: å…è®¸é…ç½®åˆ¤å®šè§„åˆ™å’Œé˜ˆå€¼

## ä¿®æ”¹æ–‡ä»¶æ¸…å•

- âœ… `backend/app/services/llm_service.py` - æ·»åŠ è§†è§‰åˆ†æåŠŸèƒ½

## æµ‹è¯•å»ºè®®

1. **é…ç½®è§†è§‰æ¨¡å‹**: å°†é¡¹ç›®LLMæ¨¡å‹æ”¹ä¸º `gpt-4o` æˆ– `qwen-vl-plus`
2. **æ‰§è¡Œæµ‹è¯•**: è¿è¡Œä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹
3. **æŸ¥çœ‹åˆ¤å®š**: æ£€æŸ¥LLMåˆ¤å®šç»“æœå’Œç†ç”±
4. **æŸ¥çœ‹è§‚å¯Ÿ**: æŸ¥çœ‹observationså­—æ®µçš„è¯¦ç»†åˆ†æ

## æ—¥æœŸ

2025-10-23
